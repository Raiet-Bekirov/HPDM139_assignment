{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4d7a20a",
   "metadata": {},
   "source": [
    "# Data Loading & Preprocessing Demonstration\n",
    "\n",
    "This notebook demonstrates how to use the data loading, preprocessing, and grouping utilities provided by the package to prepare a health dataset for intersectional fairness analysis.\n",
    "\n",
    "The data-loading and preprocessing pipeline consists of:\n",
    "\n",
    "- loading a tabular health dataset,\n",
    "- applying fairness-oriented preprocessing,\n",
    "- preparing model-ready features,\n",
    "- constructing an evaluation DataFrame aligned with model predictions and true outcomes.\n",
    "\n",
    "## Modules used in this notebook\n",
    "\n",
    "`fairness.data`\n",
    "- `load_heart_csv` - a sample data loading utility for the UCI Heart Disease dataset\n",
    "\n",
    "\n",
    "`fairness.preprocess`\n",
    "- `add_age_group` - add a fairness-oriented feature (eg. age bins)\n",
    "- `map_binary_column` - map categorical variables to numeric form\n",
    "- `apply_transforms` - sequential application of preprocessing steps\n",
    "- `preprocess_tabular` - conversion to numeric features\n",
    "- `make_train_test_split` - reproducible train/test partitionin\n",
    "\n",
    "\n",
    "`fairness.groups`\n",
    "- `make_eval_df` - constructs an evaluation DataFrame containing\n",
    "intersectional group labels aligned with model predictions and true labels\n",
    "\n",
    "## Goal\n",
    "\n",
    "The purpose of this pipeline is to produce aligned evaluation inputs for fairness analysis.\n",
    "\n",
    "Rather than returning multiple separate lists, 'make_eval-df' outputs a single DataFrame in which each row corresponds to one test-set individual.\n",
    "\n",
    "For each test individual i, the evaluation DataFrame contains:\n",
    "\n",
    "- subject_label[i] - the protected (intersectional) group label\n",
    "- y_pred[i] - the model’s prediction\n",
    "- y_true[i] - the true outcome\n",
    "\n",
    "These aligned outputs can then be passed directly to group-based fairness metrics such as accuracy differences or differential fairness.\n",
    "\n",
    "> **Note:**\n",
    "> Model training is included in this notebook only to generate predictions (y_pred) for demonstration purposes.\n",
    "> The data loading, preprocessing, and grouping modules are model-agnostic and can be used with any classifier that produces predictions aligned to the test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75e0602",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairness.data import load_heart_csv\n",
    "from fairness.preprocess import add_age_group, map_binary_column, \\\n",
    "                                apply_transforms, preprocess_tabular, \\\n",
    "                                make_train_test_split\n",
    "from fairness.groups import make_eval_df\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834739d5",
   "metadata": {},
   "source": [
    "## Load the dataset\n",
    "\n",
    "This demo uses the `heart.csv` file. \n",
    "\n",
    "Heart failure is a common event caused by cardiovascular diseases, and this dataset contains 11 features that can be used to predict possible heart failure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdb0a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "ROOT = Path.cwd().parent if Path.cwd().name == \"examples\" else Path.cwd()\n",
    "DATA_PATH = ROOT / \"data\" / \"heart.csv\"\n",
    "\n",
    "df_raw = load_heart_csv(DATA_PATH)\n",
    "df_raw.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c72364",
   "metadata": {},
   "source": [
    "## Fairness-oriented preprocessing\n",
    "\n",
    "Continuous protected attributes (like age) are binned into a small number of categories\n",
    "to produce interpretable groups and avoid tiny subgroup sample sizes.\n",
    "\n",
    "There is an optional mapping for a binary protected attribute (e.g. `Sex` from `\"M\"/\"F\"` to `1/0`),\n",
    "depending on how the dataset encodes it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56512a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a protected attribute for fairness analysis \n",
    "df_fair = add_age_group(df_raw, age_col=\"Age\", new_col=\"age_group\", bins=(0, 55, 120), labels=(\"young\", \"older\"))\n",
    "\n",
    "# map binary/categorical encodings if needed (if dataset has M/F)\n",
    "if \"Sex\" in df_fair.columns and df_fair[\"Sex\"].dtype == object:\n",
    "    df_fair = map_binary_column(df_fair, col=\"Sex\", mapping={\"M\": 1, \"F\": 0})\n",
    "\n",
    "df_fair[[\"Age\", \"age_group\", \"Sex\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ab4c30",
   "metadata": {},
   "source": [
    "### Using `apply_transforms`\n",
    "\n",
    "`apply_transforms` allows multiple `DataFrame -> DataFrame` operations to be chained togther. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763a5a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fair2 = apply_transforms(\n",
    "    df_raw,\n",
    "    transforms=[\n",
    "        lambda d: add_age_group(d, age_col=\"Age\", new_col=\"age_group\"),\n",
    "        lambda d: map_binary_column(d, col=\"Sex\", mapping={\"M\": 1, \"F\": 0}),\n",
    "    ],\n",
    ")\n",
    "\n",
    "df_fair2[[\"Age\", \"age_group\",\"Sex\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92865a93",
   "metadata": {},
   "source": [
    "## Model-oriented preprocessing\n",
    "\n",
    "In the raw dataset, variables are represented using a mixture of numeric and categorical encodings, reflecting how the data were originally defined and collected.\n",
    "\n",
    "Binary clinical indicators such as `FastingBS (0, 1)` are passed through unchanged.\n",
    "\n",
    "Variables that represent categorical concepts with 2 or ,ore possible values, such as `ChestPainType (TA, ATA, NAP, ASY)` are converted into nuermic features using one-hot encoding. This creates binary indicator columns that take value `True` if the category applies to the individual, else `False`.\n",
    "\n",
    "This allows interpretation by machine learning models.\n",
    "\n",
    "Some protected characteristics, such as sex, may be clinically relevant predictors\n",
    "and are therefore retained in the model inputs. Derived protected attributes used\n",
    "only for fairness analysis (e.g. `age_group`) are excluded. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4490b413",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = preprocess_tabular(df_fair, drop_cols=(\"age_group\",))\n",
    "df_model.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2819c726",
   "metadata": {},
   "source": [
    "## Train/test split \n",
    "\n",
    "`make_train_test_split` returns a `SplitData` container:\n",
    "- `X_train`, `X_test`\n",
    "- `y_train`, `y_test`\n",
    "\n",
    "Derived protected attributes (e.g. `age_group`) are dropped from the model features for training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43261e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = make_train_test_split(\n",
    "    df_model,\n",
    "    target_col=\"HeartDisease\",\n",
    "    test_size=0.3,\n",
    "    random_state=42,\n",
    "    stratify=True,\n",
    ")\n",
    "\n",
    "split.X_train.shape, split.X_test.shape, split.y_train.shape, split.y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7a4772",
   "metadata": {},
   "source": [
    "## Train a model to generate `y_pred`\n",
    "\n",
    "This step is outside of the toolkit's data loading and processing modules.\n",
    "It is included here to show how `y_pred` can be \n",
    "produced for fairness metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc329e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "model = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "model.fit(split.X_train, split.y_train)\n",
    "y_pred = model.predict(split.X_test)\n",
    "\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(split.y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489d2989",
   "metadata": {},
   "source": [
    "The table abvove simmarises the predictive performance of the trained classifier on the test set, using standard classification metrics.\n",
    "\n",
    "Each row corresponds to one outcome class:\n",
    "- Class 0: no heart disease\n",
    "- Class 1: heart disease present\n",
    "\n",
    "\n",
    "Accuracy is the proportion of all test-set predictions that are correct An accuracy of 0.88 means the model predicts the correct outcome for 88% of patients in the test set. In this example, the classifier achieves good accuracy, providing a suitable baseline for fairness analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a17fc37",
   "metadata": {},
   "source": [
    "## Make an evaulation DataFrame\n",
    "\n",
    "The `eval_df` DataFrame brings together all information required for fairness analysis in a single, aligned table.\n",
    "\n",
    "A list of protected attributes is provided to define intersectional groups (for example, sex × age group).\n",
    "\n",
    "Each row corresponds to one individual in the test set, with the following columns:\n",
    "\n",
    "- `subject_label`, the individual’s intersectional protected group\n",
    "- `y_pred`, the model’s prediction\n",
    "- `y_true`, the true outcome\n",
    "\n",
    "Because these columns are aligned row-by-row, fairness metrics can safely compare model performance across protected and intersectional groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d48f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_fair.loc[split.X_test.index]\n",
    "\n",
    "eval_df = make_eval_df(\n",
    "    df_test=df_test,\n",
    "    protected=[\"Sex\",\"age_group\",],\n",
    "    y_pred=y_pred,\n",
    "    y_true=split.y_test.to_numpy(),\n",
    ")\n",
    "\n",
    "eval_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03fcf597",
   "metadata": {},
   "source": [
    "## Using the evaluation DataFrame with fairness metrics\n",
    "\n",
    "At this stage of the workflow, we have constructed an evaluation DataFrame (eval_df) that brings together everything needed for fairness analysis in a single, aligned table.\n",
    "\n",
    "Different fairness metrics may expect inputs in slightly different formats. Rather than forcing every metric to accept a DataFrame, we treat eval_df as a standard representation and then extract the required inputs as needed.\n",
    "\n",
    "Many fairness metrics operate on lists, for example:\n",
    "\n",
    "- a list of group labels\n",
    "- a list of predictions\n",
    "- a list of true outcomes\n",
    "\n",
    "These are extracted from `eval_df` using helper functions in `adapters.py`, and can be passed to the fairness metrics functions as arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6da4ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairness.adapters import unpack_eval_df, make_subject_labels_dict\n",
    "\n",
    "subject_labels, predictions, true_statuses = unpack_eval_df(eval_df)\n",
    "\n",
    "subject_labels_dict = make_subject_labels_dict(\n",
    "    df_test, protected_cols=[\"Sex\", \"age_group\"]\n",
    ")\n",
    "\n",
    "print(f'subject labels list: {subject_labels[:5]}')\n",
    "print(f'predictions list: {predictions[:5]}')\n",
    "print(f'true statuses list: {true_statuses[:5]}')\n",
    "short_dict = {col: vals[:5] for col, vals in subject_labels_dict.items()}\n",
    "print(f\"subject labels dictionary: {short_dict}\")\n",
    "print(\"(first 5 entries shown)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abaef089",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be96bf8",
   "metadata": {},
   "source": [
    "## Quick pipeline for internal / development use only (not part of API)\n",
    "\n",
    "For convenience, a whole pipeline function is included at `utils/pipeline.py`. Using the code below, this can be called to get:\n",
    "- a fitted model\n",
    "- `y_test` (true values)\n",
    "- `y_pred` (predicted values)\n",
    "- `eval_df` (evaluation dataframe)\n",
    "\n",
    "It's designed for our convenience while developing the package and is not intedned to be part of the final package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b33c53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairness.preprocess import add_age_group, map_binary_column\n",
    "from fairness.utils.pipeline import run_demo_pipeline\n",
    "\n",
    "result = run_demo_pipeline(\n",
    "    csv_path=\"../data/heart.csv\",\n",
    "    target_col=\"HeartDisease\",\n",
    "    protected_cols=[\"Sex\", \"age_group\"],\n",
    "    fairness_transforms=[\n",
    "        lambda d: add_age_group(\n",
    "            d,\n",
    "            age_col=\"Age\",\n",
    "            new_col=\"age_group\",\n",
    "            bins=(0, 55, 120),\n",
    "            labels=(\"young\", \"older\"),\n",
    "        ),\n",
    "        lambda d: map_binary_column(d, col=\"Sex\", mapping={\"M\": 1, \"F\": 0}),\n",
    "    ],\n",
    "    drop_from_X=(\"age_group\",),\n",
    ")\n",
    "\n",
    "y_pred = result.y_pred\n",
    "y_pred_clean = y_pred.astype(int).tolist()\n",
    "\n",
    "y_test = result.split.y_test\n",
    "eval_df = result.eval_df  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0bf27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nEvaluation DataFrame (first 5 rows):\")\n",
    "print(eval_df.head(5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
